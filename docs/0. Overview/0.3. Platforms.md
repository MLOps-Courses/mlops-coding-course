# 0.3. Platforms

## What is an MLOps platform?

An [MLOps platform](https://aws.amazon.com/what-is/mlops/) is a comprehensive toolkit designed to facilitate the deployment, management, and operational efficiency of AI and Machine Learning (ML) projects in production environments. Essential components of an MLOps platform typically can encompass:

<figure markdown="span">
  ![CI/CD and automated ML pipeline.](https://cloud.google.com/static/architecture/images/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning-4-ml-automation-ci-cd.svg)
  <figcaption>CI/CD and automated ML pipeline (<a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#mlops_level_2_cicd_pipeline_automation">source</a>).</figcaption>
</figure>

- **Storage Systems**: These are solutions like [Amazon S3](https://aws.amazon.com/s3/) or [Google Cloud Storage](https://cloud.google.com/storage) that provide a secure space for storing datasets, models, and other essential artifacts.
- **Compute Engines**: Services such as [Kubernetes](https://kubernetes.io/) or [Databricks](https://databricks.com/) deliver the necessary computational power for training models and executing predictions.
- **Orchestrators**: Automation tools, including [Apache Airflow](https://airflow.apache.org/), [Metaflow](https://metaflow.org/), or [Prefect](https://www.prefect.io/), that streamline and manage workflows and data pipelines efficiently.
- **Model Registries**: Platforms such as [MLflow](https://mlflow.org/), [Neptune.ai](https://neptune.ai/), or [Weights and Biases](https://wandb.ai/site) that offer functionalities for tracking, versioning, and managing models.

The complexity and scale of an MLOps platform can greatly differ based on an organization's specific needs and the requirements of individual projects. While smaller teams might lean towards open-source options like [MLflow](https://mlflow.org/) for model lifecycle management and [Airflow for orchestration](https://airflow.apache.org/) due to their cost-effectiveness and versatility, larger enterprises may prefer comprehensive, fully-managed solutions such as [Databricks](https://databricks.com) or [AWS SageMaker](https://aws.amazon.com/sagemaker/) to accommodate extensive AI/ML deployments.

## Which MLOps platform is the best?

Determining the "best" MLOps platform hinges on the unique requirements, infrastructure, and technical expertise of your organization. The ideal choice is one that seamlessly integrates with your existing technology stack and optimally supports your AI/ML workflows. Consider the following steps to guide your selection:

1. **Stakeholder Engagement**: Engage with key stakeholders across data science, IT operations, and software architecture to define project requirements and objectives.
2. **Goal Alignment**: Specify your objectives and the degree of platform sophistication needed to fulfill them within your project timelines.
3. **Pilot Testing**: Conduct pilot projects to evaluate the platformâ€™s alignment with your business needs and its capacity to satisfy user expectations.

The decision is often influenced by various factors, such as the organization's familiarity with certain technologies (like Kubernetes), budgetary limitations, and the preference for flexibility versus fully-managed services.

## Why is this course not tied to a specific MLOps platform?

Market offerings frequently highlight the ease and simplicity of their MLOps platforms, sometimes at the expense of acknowledging the complexities of crafting a robust AI/ML codebase grounded in software engineering best practices. Although each platform brings its unique advantages and experiences, the foundational skills in MLOps coding are universally applicable, cutting across the specificities of individual platforms.

## Is an MLOps platform required for this course?

Intentionally designed to be platform-agnostic, this course empowers you to apply its principles within any technological ecosystem you choose. Whether you're working with specific environment management systems, leveraging various libraries, or adapting to the workflow methodologies of tools like [GitLab](https://about.gitlab.com/) or [Azure DevOps](https://azure.microsoft.com/en-us/products/devops), the course material is versatile and can be tailored to align with your organization's preferences.

## How does this course prepare you for using an MLOps platform?

Given the variety of artifacts MLOps platforms support, from Jupyter notebooks to Python packages, adopting Python packages is advocated for its robustness and maintainability. This course provides you with the essential skills to seamlessly integrate such packages within the Python ecosystem. It covers the use of testing tools like [pytest](https://docs.pytest.org/) and [coverage](https://coverage.readthedocs.io/), and package management via repositories like [PyPI](https://pypi.org/) or [Docker Hub](https://hub.docker.com/). Armed with this knowledge, you can confidently tackle other pivotal aspects of your projects, such as data and model management and orchestration, knowing your codebase is solid and dependable.

## Platform additional resources

- [The ultimate list of internal ML platforms](https://www.evidentlyai.com/ml-platforms)
