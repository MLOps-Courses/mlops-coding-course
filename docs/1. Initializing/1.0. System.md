# 1.0. System

## Which system do I need for the course?

This course is designed to be universally accessible, supporting a variety of operating systems including Linux, Chromebook, macOS, and Windows. While there are no strict hardware requirements, it's essential to ensure your computer has sufficient CPU and RAM capabilities to efficiently handle dataset processing. This flexibility ensures that regardless of your system preference or availability, you can participate fully in the course activities.

## Can I complete the course on JupyterLab or Google Colab?

Yes, JupyterLab is a supported environment for this course. However, it's important to note that the course materials are optimized for use in Visual Studio Code (VS Code), which provides a more extensive feature set tailored for our coursework. Although Jupyter notebooks and Google Colab might be adequate for the early stages of the course, such as chapter 2 on Prototyping, later exercises demand functionalities—like terminal access and file system navigation—that are more seamlessly integrated into VS Code than the mentioned platforms.

## Do I need to install other software packages?

To fully engage with the course material, you'll need to install several foundational software packages, including Python, Poetry, git, and VS Code. Each of these tools plays a crucial role in your development workflow, and detailed installation guides are available in their respective chapters within the course. Python is indispensable for the course, while the other software, though highly recommended, can be substituted with alternatives according to your personal preferences or requirements.

## Is there specific requirements for MLOps projects?

MLOps projects can vary widely in complexity and scale, ranging from simple tabular data analyses to sophisticated machine learning models like transformers. Here’s a quick guide to understand the hardware requirements based on project complexity:

- **Tabular Data Projects**: For projects using libraries like scikit-learn or XGBoost, a local setup without the need for specialized hardware, with an optional GPU for certain tasks, is often sufficient.
- **Multimedia Data Projects**: When working with TensorFlow or PyTorch for image or video data, having access to at least one GPU can significantly speed up processing.
- **Large Dataset Projects**: For advanced projects utilizing transformers or requiring extensive parallel processing, such as those using DeepSpeed, leveraging multiple GPUs across one or several machines may be necessary.

It’s advisable to start as simply as possible—for instance, developing models with sample data on a local machine—and then scale up to cloud resources like Databricks for deployment and larger-scale testing. Cloud instances can also offer the advantage of running multiple experiments in parallel, potentially accelerating your development process.

## Can I use a cloud system (e.g., Cloud Workstation, GitHub Codespaces, ...)?

Yes, the course is designed to be compatible with both local and cloud-based development environments, including platforms like GitHub Codespaces or Cloud Workstation. Cloud platforms can offer significant advantages, such as a consistent development environment for team collaboration and enhanced data security. However, it’s important to be aware of any specific setup requirements and the limitations imposed by free tiers or usage quotas of these cloud services, which might necessitate careful planning and management of your development resources.